{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c088399b-2528-4c94-a6f3-45cd53206fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-readers-wikipedia\n",
    "%pip install llama-index-llms-azure-openai\n",
    "%pip install llama-index-graph-stores-nebula\n",
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-embeddings-azure-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b2176d-5015-4bb3-9851-7d4cad6da394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall llama_index==0.8.9\n",
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4f7c8f-07e5-46cf-b902-e888a66f00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251c19c7-f2a5-45d7-bc67-3901cb5552f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "# For OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk----\"\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "\n",
    "\n",
    "# define LLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4621ddbe-6702-4fcb-a388-fbca7c0c5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "\n",
    "#azure_endpoint = \"https://.openai.azure.com/\"\n",
    "#api_version = \"2023-07-01-preview\"\n",
    "\n",
    "\n",
    "api_key = \"e------------------------------\"\n",
    "azure_endpoint = \"https://azure----------------------.openai.azure.com/\"\n",
    "\n",
    "#\"text-embedding-ada-002\"\n",
    "\n",
    "#\"gpt-35-turbo\"\n",
    "\n",
    "lc_llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embedding_llm = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d61f46-8580-41ad-9f24-6bd94876178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipython-ngql nebula3-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4068f8-673b-4333-9c92-5438e62c5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = lc_llm \n",
    "Settings.embed_model = embedding_llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2733e14e-bdcb-41ed-acfc-d2dc17e6ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEBULA_USER\"] = \"root\"\n",
    "os.environ[\"NEBULA_PASSWORD\"] = \"nebula\"  # default is \"nebula\"\n",
    "os.environ['GRAPHD_HOST'] = \"127.0.0.1\"\n",
    "os.environ[\n",
    "    \"NEBULA_ADDRESS\"\n",
    "] = \"127.0.0.1:9669\"  # assumed we have NebulaGraph installed locally\n",
    "\n",
    "space_name = \"rag_workshop\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "]  # default, could be omit if create from an empty kg\n",
    "tags = [\"entity\"]  # default, could be omit if create from an empty kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed1ce3a-9eda-4aa6-b088-1785c2cbcde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Pool Created\n",
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rag_workshop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name\n",
       "0  rag_workshop"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext ngql\n",
    "connection_string = f\"--address {os.environ['GRAPHD_HOST']} --port 9669 --user root --password {os.environ['NEBULA_PASSWORD']}\"\n",
    "%ngql {connection_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b120c9-b685-410e-b4f0-55cdb8bc4028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql CREATE SPACE IF NOT EXISTS rag_workshop(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be910e4-9a2d-4dfa-85d9-030dd99a2da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "USE rag_workshop;\n",
    "CREATE TAG IF NOT EXISTS entity(name string);\n",
    "CREATE EDGE IF NOT EXISTS relationship(relationship string);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db2d9e36-c445-4e74-bad0-48b5c76f5e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql CREATE TAG INDEX IF NOT EXISTS entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d97807a-492c-4e9e-a403-34a72972097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af1089b-f23b-4f03-b91c-5f17e558dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import download_loader\n",
    "\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "\n",
    "loader = WikipediaReader()\n",
    "\n",
    "documents = loader.load_data(\n",
    "    pages=[\"Tesla Cybertruck\"], auto_suggest=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23fc08f-6b82-4881-a42f-9bc493a244bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import KnowledgeGraphIndex\n",
    "\n",
    "kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51282226-49ff-4c85-aa43-77b273931d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index.storage_context.persist(persist_dir='./storage_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2795bd30-b9c8-426c-ba8a-503b3aebb32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141056/577445147.py:6: DeprecationWarning: Call to deprecated function (or staticmethod) from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex,  VectorStoreIndex\n",
    "from llama_index.core import ServiceContext, set_global_service_context\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=lc_llm,\n",
    "    embed_model=embedding_llm,\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir='./storage_graph', graph_store=graph_store)\n",
    "kg_index = load_index_from_storage(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a23eb40-b2bc-408b-97ae-028c4cf414aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host</th>\n",
       "      <th>Port</th>\n",
       "      <th>Status</th>\n",
       "      <th>Leader count</th>\n",
       "      <th>Leader distribution</th>\n",
       "      <th>Partition distribution</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>storaged0</td>\n",
       "      <td>9779</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>0</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storaged1</td>\n",
       "      <td>9779</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>0</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>storaged2</td>\n",
       "      <td>9779</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>1</td>\n",
       "      <td>rag_workshop:1</td>\n",
       "      <td>rag_workshop:1</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Host  Port  Status  Leader count Leader distribution  \\\n",
       "0  storaged0  9779  ONLINE             0  No valid partition   \n",
       "1  storaged1  9779  ONLINE             0  No valid partition   \n",
       "2  storaged2  9779  ONLINE             1      rag_workshop:1   \n",
       "\n",
       "  Partition distribution Version  \n",
       "0     No valid partition   3.6.0  \n",
       "1     No valid partition   3.6.0  \n",
       "2         rag_workshop:1   3.6.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install pydantic==1.10.13\n",
    "#!pip install docarray==0.32.1\n",
    "#!pip install pydantic==1.10.13\n",
    "%ngql SHOW HOSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e53d1fd-d7bf-4d2b-82e9-0aa6654dbdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import KnowledgeGraphQueryEngine\n",
    "\n",
    "nl2kg_query_engine = KnowledgeGraphQueryEngine(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=lc_llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50946e6d-3c7d-4fd1-a306-24d8a06b7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re=nl2kg_query_engine.query(\"SHOW HOSTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc14afc-5b5f-48b4-8d0f-6eb39cc75a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index_query_engine = kg_index.as_query_engine(\n",
    "    retriever_mode=\"keyword\",\n",
    "    verbose=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "583c8459-4ea8-44f0-a4d0-82be6ba16bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;32mExtracted keywords: ['Cybertruck']\n",
      "\u001b[0mINFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2e195124-02e2-4a24-aa06-f4f29d7eb6c1: ==== Range extender ====\n",
      "The dual-motor and tri-motor configurations can be o...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0e0ffd60-0029-4fe5-b1af-1464a468929c: The Tesla Cybertruck is a battery electric medium duty full-size pickup truck...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: e6163b2d-de85-466e-93fa-0c3a45a270fd: === Pilot production ===\n",
      "\n",
      "Franz von Holzhausen drove a prototype to the Peter...\n",
      "\u001b[1;3;34mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Stopped taking orders for cybertruck}]-> From customers outside north america{name: From customers outside north america}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Single motor inverter design{name: Single motor inverter design}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Single induction motor rotor/stator design{name: Single induction motor rotor/stator design}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Contemplated}]-> Quad-motor option{name: Quad-motor option}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Single gear set design{name: Single gear set design}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Had recalled all 3}]-> 878 cybertrucks sold as of that date to fix an accelerator pedal pad that could come loose{name: 878 cybertrucks sold as of that date to fix an accelerator pedal pad that could come loose}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Removed}]-> Cybertruck's pricing and specifications{name: Cybertruck's pricing and specifications}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Delivered}]-> First 10 or 12 production units{name: First 10 or 12 production units}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Planned to produce}]-> Cybertruck in 2021{name: Cybertruck in 2021}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Built}]-> Tesla cybertruck{name: Tesla cybertruck}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Built}]-> First cybertruck{name: First cybertruck}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Stopped taking orders for cybertruck from}]-> Customers outside north america{name: Customers outside north america}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Defended the design}]-> Saying that the structures of the truck would absorb an impact during a crash{name: Saying that the structures of the truck would absorb an impact during a crash}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Accepted}]-> Cybertruck reservations{name: Cybertruck reservations}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Was offered in}]-> Three models{name: Three models}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Uses}]-> A 48-volt electrical system{name: A 48-volt electrical system}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Platform approach{name: Platform approach}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Speed sensitive and damped steering{name: Speed sensitive and damped steering}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Chassis{name: Chassis}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> 18.5 in touch-screen display in the front{name: 18.5 in touch-screen display in the front}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Operates}]-> Vehicle systems{name: Vehicle systems}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Uses}]-> Can bus satellite networks{name: Can bus satellite networks}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Towing capacity}]-> Meets or exceeds ford f-150{name: Meets or exceeds ford f-150}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Is}]-> Exoskeleton{name: Exoskeleton}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Is}]-> Exoskeleton{name: Exoskeleton} <-[relationship:{relationship: Is}]- Cybertruck{name: Cybertruck}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Armor glass windows{name: Armor glass windows}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Dual-motor awd configuration{name: Dual-motor awd configuration}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Chassis{name: Chassis} <-[relationship:{relationship: Has}]- Cybertruck{name: Cybertruck}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has pre-production models in}]-> July 2023{name: July 2023}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Began production}]-> Gigafactory texas{name: Gigafactory texas}\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<b>Cybertruck is a medium duty full-size pickup truck built by Tesla, Inc. since 2023. It has a triangular body with flat sheet stainless steel panels. It offers up to 9.6 kW of vehicle-to-load (V2L) continuous AC power through five outlets, supports up to 11.5 kW AC output for vehicle-to-home (V2H), or vehicle-to-vehicle (V2V) charging, and uses a 48-volt electrical system. The Cybertruck has three models: the tri-motor all-wheel drive (AWD) \"Cyberbeast\", a dual-motor AWD model, and a rear-wheel drive (RWD) model, with EPA range estimates of 250–340 miles (400–550 km), varying by model. It also has features such as wade mode, range extender, and armor glass windows.</b>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_graph_rag = kg_index_query_engine.query(\"What is Cybertruck\")\n",
    "\n",
    "display(f\"<b>{response_graph_rag}</b>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed85a62-aa75-48ba-92e8-a4cf24eaf94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;32mExtracted keywords: ['Musk']\n",
      "\u001b[0mINFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: d5cf6b11-3513-4ee0-8eb1-ddac820f0501: === Reservations ===\n",
      "\n",
      "Beginning in November 2019, Tesla accepted Cybertruck r...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: de08cfb8-806f-4c92-8642-bd8fc7528a01: == Design ==\n",
      "\n",
      "\n",
      "=== Inspiration and styling ===\n",
      "\n",
      "According to Musk, the design...\n",
      "\u001b[1;3;34mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Musk{name: Musk} -[relationship:{relationship: Inspired by}]-> Wet nellie{name: Wet nellie} -[relationship:{relationship: Driven by}]-> James bond{name: James bond}\n",
      "Musk{name: Musk} -[relationship:{relationship: Inspired by}]-> Wet nellie{name: Wet nellie} <-[relationship:{relationship: Inspired by}]- Musk{name: Musk}\n",
      "Musk{name: Musk} -[relationship:{relationship: Involved in}]-> Design process{name: Design process}\n",
      "Musk{name: Musk} -[relationship:{relationship: Stated}]-> Final specifications and pricing would be materially different{name: Final specifications and pricing would be materially different}\n",
      "Musk{name: Musk} -[relationship:{relationship: Inspired by}]-> Blade runner{name: Blade runner}\n",
      "Musk{name: Musk} -[relationship:{relationship: Used son's quote as}]-> Inspiration for design{name: Inspiration for design}\n",
      "Musk{name: Musk} -[relationship:{relationship: Inspired by}]-> Wet nellie{name: Wet nellie}\n",
      "Musk{name: Musk} -[relationship:{relationship: Stated}]-> Final specifications and pricing would be different{name: Final specifications and pricing would be different}\n",
      "Musk{name: Musk} -[relationship:{relationship: Inspired by}]-> Blade runner{name: Blade runner} <-[relationship:{relationship: Inspired by}]- Musk{name: Musk}\n",
      "Musk{name: Musk} -[relationship:{relationship: Wanted cybertruck to have}]-> All the utility of a pick-up truck{name: All the utility of a pick-up truck}\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<b>Musk is a person mentioned in the context information who is involved in the design process of the Cybertruck, stated that final specifications and pricing would be materially different from those unveiled on the concept vehicle in 2019, and was inspired by Blade Runner and Wet Nellie for the design of the Cybertruck. Musk also used his son's quote as an inspiration for the design and wanted the Cybertruck to have all the utility of a pick-up truck.</b>\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_graph_rag = kg_index_query_engine.query(\"Who is Musk?\")\n",
    "\n",
    "display(f\"<b>{response_graph_rag}</b>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20bdbd98-c6a5-471d-90ed-cf4fba4dbab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;32mExtracted keywords: ['expensive', 'Cybertruck']\n",
      "\u001b[0mINFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2e195124-02e2-4a24-aa06-f4f29d7eb6c1: ==== Range extender ====\n",
      "The dual-motor and tri-motor configurations can be o...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0e0ffd60-0029-4fe5-b1af-1464a468929c: The Tesla Cybertruck is a battery electric medium duty full-size pickup truck...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: e6163b2d-de85-466e-93fa-0c3a45a270fd: === Pilot production ===\n",
      "\n",
      "Franz von Holzhausen drove a prototype to the Peter...\n",
      "\u001b[1;3;34mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Stopped taking orders for cybertruck}]-> From customers outside north america{name: From customers outside north america}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Single motor inverter design{name: Single motor inverter design}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Single induction motor rotor/stator design{name: Single induction motor rotor/stator design}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Contemplated}]-> Quad-motor option{name: Quad-motor option}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Single gear set design{name: Single gear set design}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Had recalled all 3}]-> 878 cybertrucks sold as of that date to fix an accelerator pedal pad that could come loose{name: 878 cybertrucks sold as of that date to fix an accelerator pedal pad that could come loose}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Removed}]-> Cybertruck's pricing and specifications{name: Cybertruck's pricing and specifications}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Delivered}]-> First 10 or 12 production units{name: First 10 or 12 production units}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Planned to produce}]-> Cybertruck in 2021{name: Cybertruck in 2021}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Built}]-> Tesla cybertruck{name: Tesla cybertruck}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Built}]-> First cybertruck{name: First cybertruck}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Stopped taking orders for cybertruck from}]-> Customers outside north america{name: Customers outside north america}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Defended the design}]-> Saying that the structures of the truck would absorb an impact during a crash{name: Saying that the structures of the truck would absorb an impact during a crash}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Accepted}]-> Cybertruck reservations{name: Cybertruck reservations}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Was offered in}]-> Three models{name: Three models}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Uses}]-> A 48-volt electrical system{name: A 48-volt electrical system}\n",
      "Cybertruck{name: Cybertruck} <-[relationship:{relationship: Limited availability}]- Tesla{name: Tesla} -[relationship:{relationship: Uses}]-> Platform approach{name: Platform approach}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Speed sensitive and damped steering{name: Speed sensitive and damped steering}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Chassis{name: Chassis}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> 18.5 in touch-screen display in the front{name: 18.5 in touch-screen display in the front}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Operates}]-> Vehicle systems{name: Vehicle systems}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Uses}]-> Can bus satellite networks{name: Can bus satellite networks}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Towing capacity}]-> Meets or exceeds ford f-150{name: Meets or exceeds ford f-150}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Is}]-> Exoskeleton{name: Exoskeleton}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Is}]-> Exoskeleton{name: Exoskeleton} <-[relationship:{relationship: Is}]- Cybertruck{name: Cybertruck}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Armor glass windows{name: Armor glass windows}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Dual-motor awd configuration{name: Dual-motor awd configuration}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has}]-> Chassis{name: Chassis} <-[relationship:{relationship: Has}]- Cybertruck{name: Cybertruck}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Has pre-production models in}]-> July 2023{name: July 2023}\n",
      "Cybertruck{name: Cybertruck} -[relationship:{relationship: Began production}]-> Gigafactory texas{name: Gigafactory texas}\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://azure-openai-98325.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<b>The pricing for the Cybertruck varies depending on the model. The base price for the single-motor RWD model is $60,990 and is set to be available in 2025. The all-wheel drive model is set to be available in 2024 at a starting price of $79,990, while the tri-motor Cyberbeast variant is offered at $99,990, also set to be available in 2024. Compared to the 2019 unveiling of the concept Cybertruck, base prices had risen by $21,000–39,000, depending on the model, an increase of 53% to 64%. Therefore, it can be said that the Cybertruck is relatively expensive, but the pricing varies depending on the model.</b>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_graph_rag = kg_index_query_engine.query(\"Is Cybertruck expensive?\")\n",
    "\n",
    "display(f\"<b>{response_graph_rag}</b>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c9411-983f-4a14-a16d-03a3f8d3bb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
